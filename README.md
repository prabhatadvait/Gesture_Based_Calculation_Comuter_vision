# âœ‹ **Gesture-Based Numeric Drawing and Real-Time Calculation System** âœ¨

This project revolutionizes how we interact with technology by enabling users to perform numeric inputs and calculations through **hand gestures**. Designed for accessibility, education, and interactive systems, this solution leverages **AI** and **Computer Vision** to provide an intuitive, real-time interface for drawing digits and symbols. Say goodbye to traditional keyboards and hello to a seamless interaction experience!

---

## ğŸ› ï¸ **Features**

- ğŸ¥ **Real-Time Gesture Tracking:** Utilizes **Mediapipe** to track hand gestures and landmarks with high precision.  
- ğŸ–¼ï¸ **Interactive Drawing Interface:** Built with **OpenCV**, providing a canvas for users to draw numeric inputs and symbols like `+`, `-`, `*`, and `/`.  
- ğŸ§  **Custom Trained Model:** A CNN model trained from scratch on a **10,000-image dataset** of hand-drawn digits and mathematical symbols ensures accuracy and adaptability.  
- âš¡ **Real-Time Calculation:** Dynamically parses and computes user-drawn equations using Pythonâ€™s `eval`.  
- ğŸ’» **Accessible and Adaptive:** Designed for diverse environments, including **smart classrooms**, **assistive technologies**, and **digital whiteboards**.  
- ğŸ”„ **Data Augmentation:** Enhances training data through techniques like rotation, flipping, and noise addition for better generalization.  

---

## ğŸ“‚ **Project Overview**

This project bridges the gap between humans and machines by introducing a gesture-based interface. The system allows users to draw digits and symbols naturally with their hands, which are then recognized and processed for real-time calculations.  

### **Core Components**  
1. **Hand Tracking:** Detects and tracks hand gestures using **Mediapipe**, ensuring smooth and accurate drawing.  
2. **Drawing Interface:** Creates a virtual canvas using **OpenCV**, capturing user input dynamically.  
3. **Model Training:** A custom **Convolutional Neural Network (CNN)** model trained on **10,000 hand-drawn images** from Kaggle to recognize digits (`0-9`) and symbols (`+`, `-`, `*`, `/`).  
4. **Real-Time Computation:** Converts recognized symbols into mathematical equations and evaluates them instantly.  

---

## ğŸ› ï¸ **Tools & Technologies Used**

### **Programming Language**  
- ğŸ **Python**  

### **Libraries & Frameworks**  
- ğŸ“¸ **Mediapipe:** For hand gesture tracking.  
- ğŸ–¼ï¸ **OpenCV:** For virtual drawing interface.  
- ğŸ§  **TensorFlow/Keras:** For training and deploying the CNN model.  
- ğŸ“Š **NumPy:** For numerical computations.  

### **Software & Editors**  
- ğŸ’» **VS Code** / **PyCharm:** For development.  
- ğŸ“¦ **Kaggle Datasets:** A curated dataset of hand-drawn images for training.  

### **Hardware Requirements**  
- ğŸ¥ Webcam  
- ğŸ–¥ï¸ Laptop or PC with at least **8GB RAM** and **2GB VRAM**  

---

## ğŸ“ˆ **System Workflow**

1. **Data Capture:**  
   - Captures real-time video using a webcam.  
   - Tracks hand landmarks to create a drawing on the canvas.  

2. **Preprocessing:**  
   - Converts drawings to grayscale, resizes them to 28x28 pixels, and normalizes them for model input.  

3. **Recognition:**  
   - A custom-trained CNN model processes the drawings to identify digits and symbols.  

4. **Equation Parsing:**  
   - Recognized symbols are converted into a mathematical equation.  

5. **Calculation:**  
   - The equation is evaluated dynamically, and the result is displayed on the interface.  

---

## ğŸ”‘ **Key Highlights**

- **Custom Model:** Our CNN model, trained on **10,000 images**, achieves high accuracy for digit and symbol recognition.  
- **Low Latency:** Processes inputs and computations in real-time, ensuring smooth user interaction.  
- **Robust Design:** Handles varying lighting conditions and drawing styles effectively.  
- **Scalability:** Designed to adapt to more complex symbols and larger datasets in the future.  

---

## ğŸ“š **Applications**

- ğŸ“ **Education:**  
  Enhance teaching and learning experiences in smart classrooms.  

- â™¿ **Accessibility:**  
  Assistive tools for individuals with motor disabilities, providing alternative input methods.  

- ğŸ’¼ **Professional Use:**  
  Ideal for collaborative whiteboarding and brainstorming in digital workspaces.  

- ğŸ¨ **Creative Spaces:**  
  Integrate gesture-based interactions for immersive artistic and interactive exhibits.  

---

## ğŸš€ **Future Scope**

1. Expand the model to include more complex mathematical symbols like parentheses and trigonometric functions.  
2. Integrate with **Augmented Reality (AR)** for immersive experiences.  
3. Develop **mobile and web-based versions** for cross-platform compatibility.  
4. Add **voice and haptic feedback** for enhanced accessibility.  
5. Train the model on diverse datasets to support multilingual symbols and inputs.  

---

## ğŸ¤ **Contributions**

Contributions are welcome! If youâ€™d like to improve the project or explore new features, feel free to fork the repository and submit a pull request.  

---

## ğŸ“œ **License**

This project is licensed under the **MIT License** â€“ youâ€™re free to use, modify, and distribute it as long as proper credit is given.  

---

## ğŸ“¨ **Contact**

For questions or collaborations, reach out to:  
- **Prabhat Kumar**  
  - LinkedIn: [Prabhat Kumar](https://www.linkedin.com/in/prabhat-kumar-1260a5259)  
  - Email: [prabhatsharma84226@gmail.com](mailto:prabhatsharma84226@gmail.com)  
